const fetch = require('node-fetch');
const Replicate = require('replicate');
const ReplicateCreditSystem = require('./credit-system-replicate');

// Simple in-memory usage tracking (in production, use a real database)
const usageDB = new Map();

// Initialize credit system
const creditSystem = new ReplicateCreditSystem();

// Store generation jobs (in production, use a database like Redis)
const generationJobs = new Map();

// Security: Password protection to prevent unauthorized usage
const ADMIN_PASSWORD = process.env.ADMIN_PASSWORD || 'HumGod2024!Secret';
const REQUIRED_PASSWORD = process.env.REQUIRED_PASSWORD || 'HumGod2024!Secret';

// Check if user has admin access
function checkAdminAccess(password) {
    return password === ADMIN_PASSWORD;
}

// Check if user has required password for generation
function checkRequiredPassword(password) {
    return password === REQUIRED_PASSWORD;
}

// Track user usage
function trackUsage(userId, generationLength) {
    const today = new Date().toDateString();
    const key = `${userId}-${today}`;
    
    if (!usageDB.has(key)) {
        usageDB.set(key, {
            userId,
            date: today,
            generations: 0,
            totalSeconds: 0,
            isPremium: false
        });
    }
    
    const usage = usageDB.get(key);
    usage.generations++;
    usage.totalSeconds += generationLength;
    
    return usage;
}

// Check if user can generate (free tier limits)
function canGenerate(userId, generationLength) {
    const usage = trackUsage(userId, generationLength);
    
    // Free tier limits - only mock audio, no real API calls
    if (!usage.isPremium) {
        if (usage.generations >= 3) {
            return { allowed: false, reason: 'Daily limit reached (3 generations). Upgrade to Premium for unlimited!' };
        }
        if (generationLength > 15) {
            return { allowed: false, reason: 'Free tier limited to 15 seconds. Upgrade to Premium for longer clips!' };
        }
    }
    
    return { allowed: true };
}

// Get user's current usage
function getUserUsage(userId) {
    const today = new Date().toDateString();
    const key = `${userId}-${today}`;
    return usageDB.get(key) || { generations: 0, totalSeconds: 0, isPremium: false };
}

// Real MusicGen API call using Replicate (premium quality!)
async function callRealMusicGen(audioData, instrument, duration, userId = 'anonymous') {
    try {
        console.log('ðŸŽµ Attempting real MusicGen conversion with Replicate...');
        
        if (!process.env.REPLICATE_API_TOKEN) {
            console.log('âŒ No Replicate API token found');
            return { success: false, error: 'Replicate API token not configured' };
        }

        const modelId = "meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb";
        const generationDuration = parseInt(duration) || 10;
        
        // Check if user has enough credits
        if (!creditSystem.hasEnoughCredits(userId, modelId, generationDuration)) {
            const cost = creditSystem.calculateCost(modelId, generationDuration);
            const userBalance = creditSystem.getUserCredits(userId);
            return { 
                success: false, 
                error: `Insufficient credits. Need ${cost} credits, have ${userBalance}. Purchase more credits to continue.`,
                creditsNeeded: cost,
                userCredits: userBalance
            };
        }
        
        const replicate = new Replicate({
            auth: process.env.REPLICATE_API_TOKEN,
        });
        
        const prompt = createMusicPrompt(instrument, audioData);
        
        console.log('ðŸŽµ Using Replicate MusicGen model...');
        
        // Use Replicate's MusicGen model (melody version for audio input)
        const output = await replicate.run(
            "meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb",
            {
                input: {
                    model_version: "melody",
                    prompt: prompt,
                    duration: Math.min(parseInt(duration) || 10, 30), // Max 30 seconds
                    input_audio: audioData ? `data:audio/wav;base64,${audioData}` : undefined,
                    continuation: false,
                    continuation_start: 0,
                    continuation_end: 0,
                    multi_band_diffusion: false,
                    normalization_strategy: "peak",
                    top_k: 250,
                    top_p: 0,
                    temperature: 1,
                    classifier_free_guidance: 3,
                    output_format: "wav"
                }
            }
        );

        if (!output || !output[0]) {
            console.log('âŒ Replicate API returned no output');
            return { success: false, error: 'No audio generated by Replicate' };
        }

        console.log('ðŸŽµ Replicate API request successful!');
        
        // Deduct credits after successful generation
        const creditDeduction = creditSystem.deductCredits(userId, modelId, generationDuration);
        console.log(`ðŸ’° Deducted ${creditDeduction.cost} credits ($${(creditDeduction.cost * 0.01).toFixed(2)}) from user ${userId}`);
        
        // Replicate returns a URL to the generated audio
        const audioUrl = output[0];
        
        // Download the audio file
        const audioResponse = await fetch(audioUrl);
        if (!audioResponse.ok) {
            throw new Error(`Failed to download audio: ${audioResponse.status}`);
        }
        
        const audioBuffer = await audioResponse.buffer();
        const audioBase64 = Buffer.from(audioBuffer).toString('base64');
        
        return {
            success: true,
            audioData: audioBase64,
            source: 'Replicate MusicGen',
            creditsUsed: creditDeduction.cost,
            remainingCredits: creditDeduction.newBalance
        };
        
    } catch (error) {
        console.error('Replicate MusicGen error:', error);
        return { success: false, error: error.message };
    }
}

// Create music prompt based on instrument and audio input
function createMusicPrompt(instrument, audioData = null) {
    const basePrompts = {
        piano: 'Generate a beautiful piano melody with classical harmony and emotional depth',
        guitar: 'Create an acoustic guitar arrangement with fingerpicking style and warm tones',
        violin: 'Generate a violin melody with expressive vibrato and classical phrasing',
        synth: 'Create a modern synthesizer track with electronic sounds and analog warmth',
        drums: 'Generate a drum track with kick, snare, hi-hats, and cymbals in a rhythmic pattern',
        bass: 'Create a bass line with deep, sustained notes and rhythmic groove'
    };
    
    let prompt = basePrompts[instrument] || basePrompts.piano;
    
    // If we have audio data, modify the prompt to reference it
    if (audioData) {
        prompt = `Based on the provided audio input (humming/beatboxing/whistling), generate a ${instrument} arrangement that follows the melody, rhythm, and style of the input. ${prompt}`;
    }
    
    return prompt;
}

// Main Vercel serverless function for MusicGen API
const mainHandler = async (req, res) => {
    // Set CORS headers
    res.setHeader('Access-Control-Allow-Origin', '*');
    res.setHeader('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
    res.setHeader('Access-Control-Allow-Headers', 'Content-Type, Authorization');
    
    if (req.method === 'OPTIONS') {
        return res.status(200).end();
    }
    
    if (req.method !== 'POST') {
        return res.status(405).json({ error: 'Method not allowed' });
    }
    
    try {
        const { audioData, instrument = 'piano', duration = '10', style = 'classical', userId = 'anonymous', confirmed = false, password } = req.body;
        
        // Security check: Require password for generation
        if (!checkRequiredPassword(password)) {
            return res.status(401).json({ 
                error: 'Unauthorized access. Password required.',
                message: 'This service is currently in private beta. Contact admin for access.',
                requiresPassword: true
            });
        }
        
        if (!audioData) {
            return res.status(400).json({ error: 'No audio data provided' });
        }
        
        // If not confirmed, return cost estimation instead of generating
        if (!confirmed) {
            const modelId = "meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb";
            const generationDuration = parseInt(duration) || 10;
            const cost = creditSystem.calculateCost(modelId, generationDuration);
            const userCredits = creditSystem.getUserCredits(userId);
            const hasEnoughCredits = creditSystem.hasEnoughCredits(userId, modelId, generationDuration);
            const userCharge = Math.max(cost + 5, Math.ceil(cost * 1.5));
            
            return res.json({
                success: false,
                requiresConfirmation: true,
                estimation: {
                    duration: generationDuration,
                    instrument: instrument,
                    costToUs: cost,
                    costToUsDollars: (cost * 0.01).toFixed(2),
                    chargeToUser: userCharge,
                    chargeToUserDollars: (userCharge * 0.01).toFixed(2),
                    profit: userCharge - cost,
                    profitDollars: ((userCharge - cost) * 0.01).toFixed(2),
                    profitMargin: cost > 0 ? (((userCharge - cost) / cost) * 100).toFixed(1) : 0
                },
                user: {
                    credits: userCredits,
                    hasEnoughCredits: hasEnoughCredits,
                    canGenerate: hasEnoughCredits
                },
                message: hasEnoughCredits ? 
                    `Ready to generate! Will cost ${userCharge} credits ($${(userCharge * 0.01).toFixed(2)})` :
                    `Insufficient credits. Need ${userCharge} credits, have ${userCredits}. Purchase more credits.`
            });
        }
        
        const generationLength = parseInt(duration) || 10;
        
        console.log(`Generating ${instrument} music from base64 audio data`);
        
        // Start async generation job (for Vercel free plan compatibility)
        const jobId = `job_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
        
        // Store job info
        generationJobs.set(jobId, {
            id: jobId,
            status: 'starting',
            userId: userId,
            instrument: instrument,
            duration: generationLength,
            createdAt: new Date(),
            result: null,
            error: null
        });
        
        // Start generation in background (don't await)
        generateMusicAsync(jobId, audioData, instrument, duration, userId);
        
        return res.json({
            success: true,
            jobId: jobId,
            status: 'started',
            message: 'ðŸŽµ Generation started! Check status with jobId.',
            checkUrl: `/api/generation-status?jobId=${jobId}`,
            estimatedTime: '30-60 seconds'
        });
        
    } catch (error) {
        console.error('Error generating music:', error);
        return res.status(500).json({ 
            success: false, 
            error: 'Internal server error during music generation.',
            details: error.message 
        });
    }
};

// Export main handler as default for Vercel
module.exports = mainHandler;

// Credit management endpoints
module.exports.getCredits = async (req, res) => {
    const { userId = 'anonymous' } = req.query;
    const credits = creditSystem.getUserCredits(userId);
    const analytics = creditSystem.getUsageAnalytics(userId);
    
    res.json({
        userId: userId,
        credits: credits,
        analytics: analytics,
        pricing: creditSystem.getPricingTiers()
    });
};

module.exports.addCredits = async (req, res) => {
    const { userId = 'anonymous', amount, source = 'purchase', password } = req.body;
    
    // Security check: Require admin password for adding credits
    if (!checkAdminAccess(password)) {
        return res.status(401).json({ 
            error: 'Unauthorized access. Admin password required.',
            message: 'Only admin can add credits.',
            requiresAdminPassword: true
        });
    }
    
    if (!amount || amount <= 0) {
        return res.status(400).json({ error: 'Invalid credit amount' });
    }
    
    const result = creditSystem.addCredits(userId, amount, source);
    
    res.json({
        success: true,
        ...result,
        message: `Added ${amount} credits to user ${userId}`
    });
};

module.exports.getCost = async (req, res) => {
    const { duration = 10, userId = 'anonymous' } = req.query;
    const modelId = "meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb";
    const cost = creditSystem.calculateCost(modelId, parseInt(duration));
    const userCredits = creditSystem.getUserCredits(userId);
    const hasEnoughCredits = creditSystem.hasEnoughCredits(userId, modelId, parseInt(duration));
    
    res.json({
        duration: parseInt(duration),
        cost: cost,
        costInDollars: (cost * 0.01).toFixed(2),
        modelId: modelId,
        userCredits: userCredits,
        hasEnoughCredits: hasEnoughCredits,
        canGenerate: hasEnoughCredits
    });
};

// Background generation function (runs outside Vercel timeout)
async function generateMusicAsync(jobId, audioData, instrument, duration, userId) {
    try {
        // Update job status
        generationJobs.set(jobId, {
            ...generationJobs.get(jobId),
            status: 'generating'
        });
        
        console.log(`ðŸŽµ Starting async generation job ${jobId} for user ${userId}`);
        
        if (!process.env.REPLICATE_API_TOKEN) {
            console.log('âŒ No Replicate API token found - using mock audio');
            // Return mock audio instead of failing
            const mockAudio = generateMockAudio(instrument, generationDuration);
            return {
                success: true,
                audioData: mockAudio,
                source: 'Mock Audio (No API token)',
                message: 'Using mock audio - Replicate API token not configured'
            };
        }

        const modelId = "meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb";
        const generationDuration = parseInt(duration) || 10;
        
        // Check credits
        if (!creditSystem.hasEnoughCredits(userId, modelId, generationDuration)) {
            const cost = creditSystem.calculateCost(modelId, generationDuration);
            const userBalance = creditSystem.getUserCredits(userId);
            console.log(`âŒ Insufficient credits for user ${userId}. Need ${cost}, have ${userBalance}`);
            
            // Return mock audio instead of failing
            const mockAudio = generateMockAudio(instrument, generationDuration);
            return {
                success: true,
                audioData: mockAudio,
                source: 'Mock Audio (Insufficient credits)',
                message: `Insufficient credits. Need ${cost} credits, have ${userBalance}. Using mock audio.`,
                creditsNeeded: cost,
                userCredits: userBalance
            };
        }
        
        const replicate = new Replicate({
            auth: process.env.REPLICATE_API_TOKEN,
        });
        
        const prompt = createMusicPrompt(instrument, audioData);
        
        console.log(`ðŸŽµ Using Replicate MusicGen model for job ${jobId}...`);
        
        // Use Replicate's MusicGen model (following their exact API format)
        const input = {
            prompt: prompt,
            model_version: "melody",
            duration: Math.min(generationDuration, 30),
            input_audio: audioData ? `data:audio/wav;base64,${audioData}` : undefined,
            continuation: false,
            continuation_start: 0,
            continuation_end: 0,
            multi_band_diffusion: false,
            normalization_strategy: "peak",
            top_k: 250,
            top_p: 0,
            temperature: 1,
            classifier_free_guidance: 3,
            output_format: "wav"
        };

        const output = await replicate.run(modelId, { input });

        if (!output || !output[0]) {
            throw new Error('No audio generated by Replicate');
        }

        console.log(`ðŸŽµ Replicate API request successful for job ${jobId}!`);
        
        // Deduct credits after successful generation
        const creditDeduction = creditSystem.deductCredits(userId, modelId, generationDuration);
        console.log(`ðŸ’° Deducted ${creditDeduction.cost} credits ($${(creditDeduction.cost * 0.01).toFixed(2)}) from user ${userId}`);
        
        // Download the generated audio
        const audioUrl = output[0];
        const audioResponse = await fetch(audioUrl);
        if (!audioResponse.ok) {
            throw new Error(`Failed to download audio: ${audioResponse.status}`);
        }
        
        const audioBuffer = await audioResponse.buffer();
        const audioBase64 = Buffer.from(audioBuffer).toString('base64');
        
        // Update job with success
        generationJobs.set(jobId, {
            ...generationJobs.get(jobId),
            status: 'completed',
            result: {
                success: true,
                audioData: audioBase64,
                source: 'Replicate MusicGen',
                creditsUsed: creditDeduction.cost,
                remainingCredits: creditDeduction.newBalance
            },
            completedAt: new Date()
        });
        
        console.log(`âœ… Generation job ${jobId} completed successfully!`);
        
    } catch (error) {
        console.error(`âŒ Generation job ${jobId} failed:`, error.message);
        
        // Update job with error
        generationJobs.set(jobId, {
            ...generationJobs.get(jobId),
            status: 'failed',
            error: error.message,
            completedAt: new Date()
        });
    }
}

// Get generation status
module.exports.getGenerationStatus = async (req, res) => {
    const { jobId } = req.query;
    
    if (!jobId) {
        return res.status(400).json({ error: 'Job ID required' });
    }
    
    const job = generationJobs.get(jobId);
    
    if (!job) {
        return res.status(404).json({ error: 'Job not found' });
    }
    
    const elapsed = job.completedAt ? 
        Math.floor((job.completedAt - job.createdAt) / 1000) :
        Math.floor((new Date() - job.createdAt) / 1000);
    
    res.json({
        jobId: jobId,
        status: job.status,
        userId: job.userId,
        instrument: job.instrument,
        duration: job.duration,
        createdAt: job.createdAt,
        completedAt: job.completedAt,
        elapsedSeconds: elapsed,
        result: job.result,
        error: job.error,
        message: getStatusMessage(job.status, elapsed)
    });
};

function getStatusMessage(status, elapsed) {
    switch (status) {
        case 'starting':
            return 'Starting generation...';
        case 'generating':
            return `Generating music... (${elapsed}s elapsed)`;
        case 'completed':
            return `Generation complete! (took ${elapsed}s)`;
        case 'failed':
            return 'Generation failed';
        default:
            return 'Unknown status';
    }
}

// New endpoint: Estimate cost for generation (before actually generating)
module.exports.estimateCost = async (req, res) => {
    const { duration = 10, instrument = 'piano', userId = 'anonymous', password } = req.body;
    
    // Security check: Require password for cost estimation
    if (!checkRequiredPassword(password)) {
        return res.status(401).json({ 
            error: 'Unauthorized access. Password required.',
            message: 'This service is currently in private beta. Contact admin for access.',
            requiresPassword: true
        });
    }
    const modelId = "meta/musicgen:671ac645ce5e552cc63a54a2bbff63fcf798043055d2dac5fc9e36a837eedcfb";
    const generationDuration = parseInt(duration) || 10;
    
    const cost = creditSystem.calculateCost(modelId, generationDuration);
    const userCredits = creditSystem.getUserCredits(userId);
    const hasEnoughCredits = creditSystem.hasEnoughCredits(userId, modelId, generationDuration);
    
    // Calculate what we'll charge user (with profit margin)
    const userCharge = Math.max(cost + 5, Math.ceil(cost * 1.5)); // At least 5 credits more, or 50% markup
    
    res.json({
        success: true,
        estimation: {
            duration: generationDuration,
            instrument: instrument,
            costToUs: cost,
            costToUsDollars: (cost * 0.01).toFixed(2),
            chargeToUser: userCharge,
            chargeToUserDollars: (userCharge * 0.01).toFixed(2),
            profit: userCharge - cost,
            profitDollars: ((userCharge - cost) * 0.01).toFixed(2),
            profitMargin: cost > 0 ? (((userCharge - cost) / cost) * 100).toFixed(1) : 0
        },
        user: {
            credits: userCredits,
            hasEnoughCredits: hasEnoughCredits,
            canGenerate: hasEnoughCredits
        },
        message: hasEnoughCredits ? 
            `Ready to generate! Will cost ${userCharge} credits ($${(userCharge * 0.01).toFixed(2)})` :
            `Insufficient credits. Need ${userCharge} credits, have ${userCredits}. Purchase more credits.`
    });
};

// Mock audio generation function
function generateMockAudio(instrument, duration) {
    // Create a simple WAV file header for browser compatibility
    const sampleRate = 44100;
    const numChannels = 1;
    const bitsPerSample = 16;
    const numSamples = sampleRate * (parseFloat(duration) || 3); // Shorter duration for testing
    const dataSize = numSamples * numChannels * (bitsPerSample / 8);
    const fileSize = 44 + dataSize;
    
    // Create WAV file header - simplified for better browser compatibility
    const header = Buffer.alloc(44);
    
    // RIFF header
    header.write('RIFF', 0);
    header.writeUInt32LE(fileSize - 8, 4);
    header.write('WAVE', 8);
    
    // fmt chunk
    header.write('fmt ', 12);
    header.writeUInt32LE(16, 16); // fmt chunk size
    header.writeUInt16LE(1, 20);  // PCM format
    header.writeUInt16LE(numChannels, 22);
    header.writeUInt32LE(sampleRate, 24);
    header.writeUInt32LE(sampleRate * numChannels * (bitsPerSample / 8), 28); // byte rate
    header.writeUInt16LE(numChannels * (bitsPerSample / 8), 32); // block align
    header.writeUInt16LE(bitsPerSample, 34);
    
    // data chunk
    header.write('data', 36);
    header.writeUInt32LE(dataSize, 40);
    
    // Generate realistic instrument audio data
    const audioData = Buffer.alloc(dataSize);
    
    // Instrument-specific configurations
    const instrumentConfigs = {
        piano: { 
            frequencies: [440, 880, 1320], // A4, A5, E6
            harmonics: [0.8, 0.4, 0.2],
            envelope: 'piano',
            attack: 0.1,
            decay: 0.3,
            sustain: 0.5,
            release: 0.8
        },
        guitar: { 
            frequencies: [330, 440, 660], // E4, A4, E5
            harmonics: [0.9, 0.6, 0.3],
            envelope: 'guitar',
            attack: 0.05,
            decay: 0.2,
            sustain: 0.7,
            release: 0.6
        },
        violin: { 
            frequencies: [880, 1320, 1760], // A5, E6, A6
            harmonics: [1.0, 0.7, 0.4],
            envelope: 'violin',
            attack: 0.2,
            decay: 0.1,
            sustain: 0.8,
            release: 0.9
        },
        synth: { 
            frequencies: [220, 440, 880], // A3, A4, A5
            harmonics: [0.6, 0.8, 0.4],
            envelope: 'synth',
            attack: 0.01,
            decay: 0.1,
            sustain: 0.9,
            release: 0.3
        },
        drums: { 
            frequencies: [60, 120, 240], // Low frequencies for drums
            harmonics: [1.0, 0.5, 0.2],
            envelope: 'drums',
            attack: 0.001,
            decay: 0.1,
            sustain: 0.1,
            release: 0.2
        },
        bass: { 
            frequencies: [110, 220, 330], // A2, A3, E4
            harmonics: [1.0, 0.6, 0.3],
            envelope: 'bass',
            attack: 0.05,
            decay: 0.2,
            sustain: 0.8,
            release: 0.7
        }
    };
    
    const config = instrumentConfigs[instrument] || instrumentConfigs.piano;
    
            for (let i = 0; i < numSamples; i++) {
                const time = i / sampleRate;
                let sample = 0;
                
                // Create musical patterns instead of constant tones
                const beatTime = time * 2; // 2 beats per second
                const measureTime = time * 0.5; // 4 beats per measure
                
                // Generate multiple frequencies with harmonics and musical patterns
                for (let j = 0; j < config.frequencies.length; j++) {
                    const freq = config.frequencies[j];
                    const harmonic = config.harmonics[j];
                    
                    // Create rhythmic patterns
                    let rhythmPattern = 1;
                    if (config.envelope === 'drums') {
                        // Drum pattern: kick on 1 and 3, snare on 2 and 4
                        const beat = Math.floor(beatTime) % 4;
                        if (j === 0) { // Kick drum
                            rhythmPattern = (beat === 0 || beat === 2) ? 1 : 0;
                        } else if (j === 1) { // Snare
                            rhythmPattern = (beat === 1 || beat === 3) ? 1 : 0;
                        } else { // Hi-hat
                            rhythmPattern = 0.3 + 0.2 * Math.sin(beatTime * Math.PI * 2);
                        }
                    } else {
                        // Melodic instruments: create arpeggios and melodies
                        const noteTime = time * 0.5; // Slower note changes
                        const noteIndex = Math.floor(noteTime * 4) % 8; // 8-note pattern
                        const noteFreqs = [1, 1.25, 1.5, 1.25, 1, 0.75, 0.5, 0.75]; // Musical intervals
                        rhythmPattern = noteFreqs[noteIndex] * (0.7 + 0.3 * Math.sin(noteTime * Math.PI));
                    }
                    
                    // Add some vibrato for realism
                    const vibrato = 1 + 0.02 * Math.sin(2 * Math.PI * 3 * time);
                    const wave = Math.sin(2 * Math.PI * freq * time * vibrato) * harmonic * rhythmPattern;
                    
                    // Add some harmonic content
                    if (j === 0) {
                        sample += wave;
                        sample += Math.sin(2 * Math.PI * freq * 2 * time * vibrato) * harmonic * 0.3 * rhythmPattern; // Octave
                        sample += Math.sin(2 * Math.PI * freq * 3 * time * vibrato) * harmonic * 0.1 * rhythmPattern; // Fifth
                    } else {
                        sample += wave;
                    }
                }
        
                // Apply ADSR envelope with musical variation
                let envelope = 1.0;
                
                // Create note-based envelope (each note gets its own attack/decay)
                const noteTime = time * 0.5; // Slower note changes
                const noteIndex = Math.floor(noteTime * 4) % 8;
                const noteStart = noteIndex / 4; // When this note starts
                const noteEnd = (noteIndex + 1) / 4; // When this note ends
                const noteProgress = (time - noteStart) / (noteEnd - noteStart);
                
                if (noteProgress >= 0 && noteProgress <= 1) {
                    // Individual note envelope
                    if (noteProgress < 0.1) {
                        envelope = noteProgress / 0.1; // Quick attack
                    } else if (noteProgress < 0.8) {
                        envelope = 1 - (noteProgress - 0.1) * 0.3; // Slight decay
                    } else {
                        envelope = 0.7 * (1 - noteProgress) / 0.2; // Quick release
                    }
                } else {
                    envelope = 0; // Silence between notes
                }
                
                // Apply instrument-specific envelope
                if (config.envelope === 'piano') {
                    envelope *= Math.exp(-time * 0.5) * (1 - Math.exp(-time * 10));
                } else if (config.envelope === 'guitar') {
                    envelope *= Math.exp(-time * 0.3) * (1 - Math.exp(-time * 8));
                } else if (config.envelope === 'violin') {
                    envelope *= Math.exp(-time * 0.2) * (1 - Math.exp(-time * 6));
                } else if (config.envelope === 'synth') {
                    envelope *= 0.8 + 0.2 * Math.sin(2 * Math.PI * 0.3 * time);
                } else if (config.envelope === 'drums') {
                    envelope *= Math.exp(-time * 4) * (1 - Math.exp(-time * 30));
                } else if (config.envelope === 'bass') {
                    envelope *= Math.exp(-time * 0.4) * (1 - Math.exp(-time * 8));
                }
        
        sample *= envelope;
        
        // Add some noise for realism
        if (config.envelope === 'drums') {
            sample += (Math.random() - 0.5) * 0.1;
        }
        
        // Add some reverb effect
        if (i > 1000) {
            sample += audioData.readInt16LE((i - 1000) * 2) * 0.1;
        }
        
        // Normalize and convert to 16-bit integer
        sample = Math.max(-1, Math.min(1, sample * 0.3));
        const intSample = Math.round(sample * 32767);
        audioData.writeInt16LE(intSample, i * 2);
    }
    
    // Combine header and audio data
    const wavBuffer = Buffer.concat([header, audioData]);
    return wavBuffer.toString('base64');
}
